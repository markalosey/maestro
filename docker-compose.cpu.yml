services:
  # PostgreSQL database
  postgres:
    image: pgvector/pgvector:pg15
    container_name: maestro-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-maestro_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-maestro_password}
      POSTGRES_DB: ${POSTGRES_DB:-maestro_db}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - maestro-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-maestro_user} -d ${POSTGRES_DB:-maestro_db}"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Nginx reverse proxy - single entry point for the application
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    image: maestro-nginx
    container_name: maestro-nginx
    ports:
      - "${MAESTRO_PORT:-80}:80"
    depends_on:
      - backend
      - frontend
    networks:
      - maestro-network
    restart: unless-stopped

  backend:
    build:
      context: ./maestro_backend
      dockerfile: Dockerfile
    image: maestro-backend
    container_name: maestro-backend
    env_file:
      - .env
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - maestro-data:/app/ai_researcher/data
      - ./maestro_model_cache:/root/.cache/huggingface
      - ./maestro_datalab_cache:/root/.cache/datalab
      - ./reports:/app/reports
      - ./maestro_backend/data:/app/data
      - /Users/mlosey/maestro-bulk-docs:/app/bulk_docs
    working_dir: /app
    environment:
      - MAX_WORKER_THREADS=${MAX_WORKER_THREADS:-10}
      - TZ=${TZ:-UTC}
      - LOG_LEVEL=${LOG_LEVEL:-ERROR}
      # Force CPU mode
      - FORCE_CPU_MODE=true
      - PREFERRED_DEVICE_TYPE=cpu
      # CORS configuration for reverse proxy support
      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS:-*}
      # Allow all origins in development mode when using nginx proxy
      - ALLOW_CORS_WILDCARD=${ALLOW_CORS_WILDCARD:-true}
      # PostgreSQL connection
      - DATABASE_URL=postgresql://${POSTGRES_USER:-maestro_user}:${POSTGRES_PASSWORD:-maestro_password}@${POSTGRES_HOST:-postgres}:${POSTGRES_PORT:-5432}/${POSTGRES_DB:-maestro_db}
      # Admin credentials for initial setup
      - ADMIN_USERNAME=${ADMIN_USERNAME:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin123}
      # JWT Secret for authentication
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-your-secret-key-change-this}
    networks:
      - maestro-network
    # No GPU configuration for CPU-only mode

  frontend:
    build:
      context: ./maestro_frontend
      dockerfile: Dockerfile
    image: maestro-frontend
    container_name: maestro-frontend
    depends_on:
      - backend
    networks:
      - maestro-network
    environment:
      # API URLs (optional - using relative URLs through nginx proxy by default)
      - VITE_SERVER_TIMEZONE=${VITE_SERVER_TIMEZONE:-UTC}
      - TZ=${TZ:-UTC}
      - LOG_LEVEL=${LOG_LEVEL:-ERROR}

  doc-processor:
    build:
      context: ./maestro_backend
      dockerfile: Dockerfile
    image: maestro-doc-processor
    container_name: maestro-doc-processor
    env_file:
      - .env
    command: ["python", "-u", "services/background_document_processor.py"]
    working_dir: /app
    volumes:
      - maestro-data:/app/ai_researcher/data
      - ./maestro_model_cache:/root/.cache/huggingface
      - ./maestro_datalab_cache:/root/.cache/datalab
      - ./reports:/app/reports
      - ./maestro_backend/data:/app/data
    depends_on:
      - backend
    networks:
      - maestro-network
    environment:
      - TZ=${TZ:-UTC}
      - LOG_LEVEL=${LOG_LEVEL:-ERROR}
      # PostgreSQL connection - same as backend
      - DATABASE_URL=postgresql://${POSTGRES_USER:-maestro_user}:${POSTGRES_PASSWORD:-maestro_password}@${POSTGRES_HOST:-postgres}:${POSTGRES_PORT:-5432}/${POSTGRES_DB:-maestro_db}
      # Force CPU mode
      - FORCE_CPU_MODE=true
      - PREFERRED_DEVICE_TYPE=cpu
    # No GPU configuration for CPU-only mode

  cli:
    build:
      context: ./maestro_backend
      dockerfile: Dockerfile
    image: maestro-cli
    container_name: maestro-cli
    env_file:
      - .env
    command: ["bash"]
    stdin_open: true
    tty: true
    working_dir: /app
    volumes:
      - maestro-data:/app/ai_researcher/data
      - ./maestro_model_cache:/root/.cache/huggingface
      - ./maestro_datalab_cache:/root/.cache/datalab
      - ./reports:/app/reports
      - ./maestro_backend/data:/app/data
    depends_on:
      - backend
    networks:
      - maestro-network
    environment:
      - TZ=${TZ:-UTC}
      - LOG_LEVEL=${LOG_LEVEL:-ERROR}
      # Force CPU mode
      - FORCE_CPU_MODE=true
      - PREFERRED_DEVICE_TYPE=cpu
    # No GPU configuration for CPU-only mode

  # Optional local LLM service (uncomment if using)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: maestro-ollama
  #   ports:
  #     - "${LOCAL_LLM_HOST:-127.0.0.1}:${LOCAL_LLM_PORT:-5000}:${LOCAL_LLM_INTERNAL_PORT:-11434}"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   networks:
  #     - maestro-network
  #   restart: unless-stopped

volumes:
  postgres-data:
  maestro-data:
  # Uncomment if using local LLM
  # ollama-data:

networks:
  maestro-network:
    driver: bridge